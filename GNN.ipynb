{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpittet/anaconda3/envs/ma4/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pecanpy import pecanpy as pp\n",
    "import utils\n",
    "import networkx as nx\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from training_gnn import train_gnn\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation of hyperparamters in Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training for turku with model_name=gat, head=2, nb_conv=3, out_channels=8\n",
      "True\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m ids \u001b[39m=\u001b[39m df_features[\u001b[39m'\u001b[39m\u001b[39mstop_I\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     48\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mall(np\u001b[39m.\u001b[39msort(ids) \u001b[39m==\u001b[39m df_features[\u001b[39m'\u001b[39m\u001b[39mstop_I\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues))\n\u001b[0;32m---> 49\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m\n\u001b[1;32m     50\u001b[0m targets_handcrafted \u001b[39m=\u001b[39m df_features[\u001b[39m\"\u001b[39m\u001b[39mcity_center\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     51\u001b[0m features_handcrafted \u001b[39m=\u001b[39m df_features\u001b[39m.\u001b[39mdrop([\u001b[39m\"\u001b[39m\u001b[39mstop_I\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcity_center\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcity\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mUnnamed: 0\u001b[39m\u001b[39m\"\u001b[39m],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalues\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "model_attempts = []  # List to store the attempts for different models\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Iterate over the two model names: 'gat' and 'gnn'\n",
    "for model_name in ['gat', 'gnn']:\n",
    "    best_heads = -1\n",
    "    best_nb_graph_conv = -1\n",
    "    best_out_channels = -1\n",
    "    best_score = -1\n",
    "    attempts = []  # List to store the attempts for a specific model configuration\n",
    "\n",
    "    # Set the hyperparameter ranges based on the model name\n",
    "    if model_name == 'gat':\n",
    "        heads = [2, 4, 8]\n",
    "        nb_convs = [3, 5]\n",
    "        out_channels = [8, 16, 32]\n",
    "    else:\n",
    "        heads = [0]\n",
    "        nb_convs = [3, 5, 10]\n",
    "        out_channels = [16, 32, 64, 128]\n",
    "\n",
    "    # Iterate over the hyperparameters\n",
    "    for head in heads:\n",
    "        for nb_conv in nb_convs:\n",
    "            for out_channel in out_channels:\n",
    "                f1_train = []  # List to store F1 scores for training set\n",
    "                f1_val = []  # List to store F1 scores for validation set\n",
    "\n",
    "                # Iterate over the cities\n",
    "                for city in [\"turku\", \"detroit\", \"paris\", \"adelaide\"]:\n",
    "                    # Set the random seed for reproducibility\n",
    "                    random.seed(seed)\n",
    "                    np.random.seed(seed)\n",
    "                    torch.manual_seed(seed)\n",
    "                    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "                    print(f\"starting training for {city} with model_name={model_name}, head={head}, nb_conv={nb_conv}, out_channels={out_channel}\")\n",
    "                    \n",
    "                    # Load all featrues\n",
    "                    city_name = city\n",
    "                    data_dir = 'data'\n",
    "                    df_features = pd.read_csv(os.path.join(data_dir,\"handcrafted_features.csv\"))\n",
    "                    df_features = df_features[df_features[\"city\"]==city]\n",
    "                    targets_handcrafted = df_features[\"city_center\"].values\n",
    "                    features_handcrafted = df_features.drop([\"stop_I\", \"name\", \"city_center\", \"city\",\"Unnamed: 0\"],axis=1).values\n",
    "                    graph = nx.read_edgelist(os.path.join(data_dir, city_name, 'adj_mat.edg'), create_using=nx.DiGraph)\n",
    "\n",
    "                    adj_mat = nx.adjacency_matrix(graph, weight=None) # not weighted\n",
    "                    edge_index, _ = pyg.utils.from_scipy_sparse_matrix(adj_mat)\n",
    "                    # Split train and test split\n",
    "                    train_ids, test_ids = train_test_split(\n",
    "                        np.arange(features_handcrafted.shape[0]), test_size=0.2, stratify=targets_handcrafted, random_state=seed\n",
    "                    )\n",
    "\n",
    "                    train_ids, val_ids = train_test_split(\n",
    "                        train_ids, test_size=0.2, stratify=targets_handcrafted[train_ids], random_state=seed\n",
    "                    )\n",
    "                    #Â Scale the features\n",
    "                    standard_scaler = StandardScaler()\n",
    "                    standard_scaler.fit(features_handcrafted[train_ids])\n",
    "                    features_handcrafted = standard_scaler.transform(features_handcrafted)\n",
    "\n",
    "                    # Create data\n",
    "                    d = Data(\n",
    "                        x=torch.from_numpy(features_handcrafted),\n",
    "                        y=torch.tensor(targets_handcrafted, dtype=torch.float).clone(),\n",
    "                        edge_index=edge_index.clone(),\n",
    "                    )\n",
    "\n",
    "                    pos_weight = np.sum(targets_handcrafted[train_ids] == 0) / np.sum(targets_handcrafted[train_ids] == 1)\n",
    "                    # train the model\n",
    "                    results_gat = train_gnn(\n",
    "                        [d],\n",
    "                        train_ids,\n",
    "                        val_ids,\n",
    "                        test_ids,\n",
    "                        pos_weight=pos_weight,\n",
    "                        model_name=model_name,\n",
    "                        lr=1e-3,\n",
    "                        epochs=200,\n",
    "                        out_channels_graph=out_channel,\n",
    "                        in_channels_graph=18,\n",
    "                        heads=head,\n",
    "                        nb_graph_conv=nb_conv,\n",
    "                        dropout=0.0\n",
    "                    )\n",
    "                    # Append the results\n",
    "                    f1_train.append(results_gat[0]['train'][\"1\"][\"f1-score\"])\n",
    "                    f1_val.append(results_gat[1])\n",
    "                \n",
    "                # Compute average score over 4 cities and save the best model\n",
    "                avg_f1_train = np.mean(f1_train)\n",
    "                avg_f1_val = np.mean(f1_val)\n",
    "                attempts.append({\"model_name\":model_name,\"head\":head,\"nb_conv\":nb_conv,\"out_channel\":out_channel,\"train_f1\": avg_f1_train, \"val_f1\": avg_f1_val})\n",
    "\n",
    "                print(f'\\t|| Avg train F1-score : {avg_f1_train}, Avg val F1-score : {avg_f1_val}', end='\\r')\n",
    "                print()\n",
    "\n",
    "                if avg_f1_val  > best_score:\n",
    "                    best_score = avg_f1_val\n",
    "                    best_heads = head\n",
    "                    best_nb_graph_conv = nb_conv\n",
    "                    best_out_channels = out_channel\n",
    "\n",
    "    print(f\"best parameters with model_name={model_name}, head={best_heads}, nb_conv={best_nb_graph_conv}, out_channels={best_out_channels}\")\n",
    "    model_attempts.append(attempts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"save_gnns.json\",\"w\") as f:\n",
    "    json.dump(model_attempts,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train personalized model per city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bordeaux\n",
      "Pos weight : 5.426900584795321\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "helsinki\n",
      "Pos weight : 6.6279863481228665\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "rome\n",
      "Pos weight : 5.908093278463649\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "luxembourg\n",
      "Pos weight : 6.734513274336283\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "brisbane\n",
      "Pos weight : 4.839167455061495\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "canberra\n",
      "Pos weight : 5.034129692832765\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "nantes\n",
      "Pos weight : 6.166666666666667\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "kuopio\n",
      "Pos weight : 6.02\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "palermo\n",
      "Pos weight : 3.9361702127659575\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "toulouse\n",
      "Pos weight : 6.773722627737226\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "berlin\n",
      "Pos weight : 5.05761316872428\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "rennes\n",
      "Pos weight : 3.6391752577319587\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "sydney\n",
      "Pos weight : 6.368421052631579\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "turku\n",
      "Pos weight : 4.5327102803738315\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "detroit\n",
      "Pos weight : 7.134228187919463\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "lisbon\n",
      "Pos weight : 6.736752136752137\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "grenoble\n",
      "Pos weight : 5.142857142857143\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "melbourne\n",
      "Pos weight : 5.545120671563484\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "adelaide\n",
      "Pos weight : 2.6674259681093395\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "winnipeg\n",
      "Pos weight : 5.68724279835391\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "paris\n",
      "Pos weight : 3.0832888414308597\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "dublin\n",
      "Pos weight : 6.924119241192412\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "venice\n",
      "Pos weight : 6.5886075949367084\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "prague\n",
      "Pos weight : 5.042201834862385\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n",
      "belfast\n",
      "Pos weight : 4.448888888888889\n",
      "Training GNN...\n",
      "*******************************\n",
      "Training GAT...\n",
      "\n",
      "***********************************************\n",
      "***********************************************\n"
     ]
    }
   ],
   "source": [
    "# Run on all cities \n",
    "cities_loop_gnn('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
